:kubernetes-version: v1.18.6
:minikube-version: v1.12.1
:maven-version: 3.6.3
:java-version: 11

= Setup
include::_attributes.adoc[]

[#prerequisite]
== Prerequisite CLI tools

The following CLI tools are required for running the exercises in this tutorial. 
Please have them installed and configured before you get started with any of the tutorial chapters.

[cols="4*^,4*.",options="header,+attributes"]
|===
|**Tool**|**macOS**|**Fedora**|**windows**

| `Git`
| https://git-scm.com/download/mac[Download]
| https://git-scm.com/download/linux[Download]
| https://git-scm.com/download/win[Download]

| `Docker`
| https://docs.docker.com/docker-for-mac/install[Docker for Mac]
| `dnf install docker`
| https://docs.docker.com/docker-for-windows/install[Docker for Windows]

|`Kcat`
|https://github.com/edenhill/kcat[Download] or `brew install kcat`
|https://github.com/edenhill/kcat[Download]
|https://github.com/edenhill/kcat[Download]

| https://httpie.org/[httpie]
| `brew install httpie`
| `dnf install httpie`
| https://httpie.org/doc#windows-etc

|===

IMPORTANT: An alternative for running `kcat` is to use the following Docker command and image  `docker run -it edenhill/kcat:1.7.0 kcat`

[#downloadconfiguresources]
== Download & Configure Tutorial Sources

:folder: kafka-tutorial
Before we start setting up the environment, let’s clone the tutorial sources and set the `TUTORIAL_HOME` environment variable to point to the root directory of the tutorial:

[.console-input]
[source,bash,subs="attributes+,+macros"]
----
git clone {tutorial-url} {folder}
----

[.console-input]
[source,bash,subs="attributes+,+macros"]
----
export TUTORIAL_HOME="$(pwd)/{folder}"
----

[.console-input]
[source,bash,subs="attributes+,+macros"]
----
cd $TUTORIAL_HOME
----

[#redhataccount]
== Create a Red Hat account

You need a Red Hat account to provision a managed Kafka instance. If you don’t have a Red Hat account, this is how you can create one: 

Go to https://console.redhat.com[console.redhat.com]. 

Click the *Register for a Red Hat account* link to create a Red Hat account.

image::register-redhat-account.png[width=60%]

Be sure to select a *Personal account* type.


[#kafka]
== Provision a Kafka instance

Go to https://console.redhat.com[console.redhat.com] and log in with your Red Hat account.

On the https://console.redhat.com[console.redhat.com] landing page, select *Application Services* from the menu on the left.

On the Application Services landing page, select *Streams for Apache Kafka → Kafka Instances*.

image::rhosak-kafka-instances.png[]

On the Kafka Instances overview page, click the *Create Kafka* instance button. Choose a name and a region for your Kafka instance and click *Create instance*. From there, a managed Kafka instance will be provisioned for you. After a couple of minutes, your instance should be marked as ready. 

image::rhosak-kafka-instance-ready.png[]

[#serviceaccount]
== Create a Service Account

To connect your applications or services to a Streams for Apache Kafka instance, you need to create a service account.

On the *Kafka Instances* overview page, select the *Options* icon (the three dots) for the Kafka instance you just created. Select *View connection information*.

Copy the *Bootstrap server* endpoint to a secure location. You will need this when connecting to your Kafka instance.

Click *Create service account* to set up the service account. Enter a unique service account name and an optional description, and click *Create*.

Copy the generated *Client ID* and *Client Secret* to a secure location. These are the credentials that you’ll use to connect to this Kafka instance.

After saving the generated credentials, select the confirmation check box and close the Credentials window.

image::rhosak-service-account.png[]

[#serviceaccountpermissions]
== Set Permissions for the Service Account

After you create a service account to connect to a Kafka instance, you must also set the appropriate level of access for that new account in the Access Control List (ACL) of the Kafka instance. OpenShift Streams for Apache Kafka uses ACLs provided by Kafka that enable you to manage how other user accounts and service accounts are permitted to interact with the Kafka resources that you create.

On the *Kafka Instances* page, click the name of the Kafka instance you created before.

Click the *Access* tab to view the current ACL for this instance.

image::rhosak-default-access.png[]

Click *Manage access*, use the *Account* drop-down menu to select the service account that you previously created, and click *Next*.

Under *Assign Permissions*, use the drop-down menus to set the permissions shown in the following table for this service account. Click *Add* to add each new resource permission.

These permissions enable applications associated with the service account to create and delete topics in the instance, to produce and consume messages in any topic in the instance, and to use any consumer group and any producer.

.Example ACL permissions for a new service account
[cols="25%,25%,25%,25%"]
|===
h|Resource type
h|Resource identifier and value
h|Access type
h|Operation

|`Topic`
|`Is` = `*`
|`Allow`
|`All`

|`Consumer group`
|`Is` = `*`
|`Allow`
|`Read`

|`Transactional ID`
|`Is` = `*`
|`Allow`
|`All`
|===

image::rhosak-access-serviceaccount.png[]

After you add these permissions for the service account, click *Save* to finish.

[#verifykafka]
== Verify the Kafka instance

Using your preferred text editor, open the file at `$TUTORIAL_HOME/apps/env`. Replace the placeholders with the values you copied before. Save the file.

[.console-input]
[source,text]
----
BOOTSTRAP_SERVER=<Kafka bootstrap url>

CLIENT_ID=<service account client id>

CLIENT_SECRET=<service account client secret>

----

Open a new terminal to run Kafka commands.

Source the environment file to set the environment variables for the Kafka instance bootstrap URL, and the service account ID and secret.

[.console-input]
[source, bash-shell]
----
source $TUTORIAL_HOME/apps/env
----

Verify that the Kafka instance is correctly started and configured by running the following command:

[tabs]
====
kcat::
+
--
[.console-input]
[source, bash-shell]
----
kcat -b $BOOTSTRAP_SERVER -X security.protocol=SASL_SSL -X sasl.mechanisms=PLAIN -X sasl.username="$CLIENT_ID" -X sasl.password="$CLIENT_SECRET" -L
----
--
kcat in Docker::
+
--
[.console-input]
[source, bash-shell]
----
docker run --rm -it edenhill/kcat:1.7.0 -b $BOOTSTRAP_SERVER -X security.protocol=SASL_SSL -X sasl.mechanisms=PLAIN -X sasl.username="$CLIENT_ID" -X sasl.password="$CLIENT_SECRET" -L
----
--
====

[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Metadata for all topics (from broker -1: sasl_ssl://bernard-tm-c-mmjsvmjpm-c--rskqa.bf2.kafka.rhcloud.com:443/bootstrap):
 3 brokers:
  broker 0 at broker-0-bernard-tm-c-mmjsvmjpm-c--rskqa.bf2.kafka.rhcloud.com:443
  broker 2 at broker-2-bernard-tm-c-mmjsvmjpm-c--rskqa.bf2.kafka.rhcloud.com:443
  broker 1 at broker-1-bernard-tm-c-mmjsvmjpm-c--rskqa.bf2.kafka.rhcloud.com:443 (controller)
 0 topics:
----
